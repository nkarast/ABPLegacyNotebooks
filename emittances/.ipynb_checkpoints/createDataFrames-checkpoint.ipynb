{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Emittance DataFrames \n",
    "~ N. Karastathis (2017)\n",
    "\n",
    "The idea behind this notebook is to create a (large) flat dataframe that contains all the emittance estimated by the `LuminosityFollowUp` analysis for further visualization and analysis.\n",
    "\n",
    "The script is looping in your fill list pulling the data out of the stored pickles and creates more informative features such as the growth and the percentage difference of the emittance measured at different instances during the LHC cycle.\n",
    "\n",
    "You could also add fill numbers in the `blacklist` which means that these specific fills will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/eos/user/n/nkarast/myLibrary/init.ipynb :: Ignoring warnings.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Main info for file making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder     = '/eos/project/l/lhc-lumimod/LuminosityFollowUp/2018/procdata/'\n",
    "output_folder    = '/eos/user/n/nkarast/LHC/2018/FollowUp/pickles/'\n",
    "summary_filename = 'summaryEmittanceDataFrame_2018_periodB.pkl.gz'\n",
    "growth_filename  = 'summaryEmittanceGrowthDataFrame_2018_periodB.pkl.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6570, 6573, 6574, 6579, 6583, 6584, 6592, 6594, 6595, 6611, 6612, 6613, 6614, 6615, 6616, 6617, 6618, 6620, 6621, 6624, 6628, 6629, 6633, 6636, 6638, 6639, 6640, 6641, 6642, 6643, 6645, 6646, 6648, 6650, 6654, 6659, 6662, 6663, 6666, 6672, 6674, 6675, 6677, 6681, 6683, 6688, 6690, 6693, 6694, 6696, 6699, 6700, 6702, 6706, 6709, 6710, 6711, 6712, 6714, 6719, 6724, 6729, 6731, 6733, 6737, 6738, 6741, 6744, 6747, 6749, 6751, 6752, 6755, 6757, 6759, 6761, 6762, 6763, 6768, 6770, 6772, 6773, 6774, 6776, 6778, 6819, 6843, 6847, 6850, 6854, 6858, 6860, 6864, 6868, 6874, 6877, 6879, 6881, 6882, 6884, 6885, 6890, 6891, 6892, 6901, 6904, 6909, 6911, 6912, 6913, 6919, 6921, 6923, 6924, 6925, 6927, 6929, 6931, 6939, 6940, 6942, 6944, 6946, 6953, 6956, 6957, 6960, 6961, 6966, 6998, 7003, 7005, 7006, 7008, 7013, 7017, 7018, 7020, 7024, 7026, 7031, 7033, 7035, 7036, 7037]\n"
     ]
    }
   ],
   "source": [
    "flist = [int(x.split('_')[-1]) for x in glob.glob(input_folder+\"*\")];\n",
    "print(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Summary Cycle DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Filename of output file given for dataframe exists. Checking if it is up-to-date...\n",
      "[WARN] The old dataframe has already the fills : [[6659, 6662, 6663, 6666, 6672, 6744, 6674, 6675, 6677, 6681, 6683, 6688, 6690, 6693, 6694, 6757, 6696, 6570, 6699, 6700, 6573, 6574, 6749, 6731, 6706, 6579, 6709, 6710, 6583, 6584, 6714, 6702, 6719, 6592, 6752, 6594, 6595, 6724, 6729, 6711, 6733, 6712, 6738, 6611, 6612, 6613, 6614, 6615, 6616, 6617, 6618, 6747, 6620, 6621, 6751, 6624, 6755, 6628, 6629, 6737, 6633, 6759, 6636, 6638, 6639, 6640, 6641, 6642, 6643, 6645, 6646, 6648, 6650, 6654, 6741]] dropping them.\n",
      "Working on fill 6761\n",
      "Working on fill 6762\n",
      "Working on fill 6763\n",
      "Working on fill 6768\n",
      "Working on fill 6770\n",
      "Working on fill 6772\n",
      "Working on fill 6773\n",
      "Working on fill 6774\n",
      "Working on fill 6776\n",
      "Working on fill 6778\n",
      "Working on fill 6819\n",
      "--> Files for fill 6819 not found. Skipping it\n",
      "Working on fill 6843\n",
      "Working on fill 6847\n",
      "Working on fill 6850\n",
      "Working on fill 6854\n",
      "Working on fill 6858\n",
      "Working on fill 6860\n",
      "Working on fill 6864\n",
      "Working on fill 6868\n",
      "Working on fill 6874\n",
      "Working on fill 6877\n",
      "Working on fill 6879\n",
      "Working on fill 6881\n",
      "Working on fill 6882\n",
      "Working on fill 6884\n",
      "Working on fill 6885\n",
      "Working on fill 6890\n",
      "Working on fill 6891\n",
      "Working on fill 6892\n",
      "Working on fill 6901\n",
      "Working on fill 6904\n",
      "Working on fill 6909\n",
      "Working on fill 6911\n",
      "Working on fill 6912\n",
      "Working on fill 6913\n",
      "Working on fill 6919\n",
      "Working on fill 6921\n",
      "Working on fill 6923\n",
      "Working on fill 6924\n",
      "Working on fill 6925\n",
      "Working on fill 6927\n",
      "Working on fill 6929\n",
      "Working on fill 6931\n",
      "Working on fill 6939\n",
      "Working on fill 6940\n",
      "Working on fill 6942\n",
      "Working on fill 6944\n",
      "Working on fill 6946\n",
      "Working on fill 6953\n",
      "Working on fill 6956\n",
      "Working on fill 6957\n",
      "Working on fill 6960\n",
      "Working on fill 6961\n",
      "Working on fill 6966\n",
      "Working on fill 6998\n",
      "Working on fill 7003\n",
      "Working on fill 7005\n",
      "Working on fill 7006\n",
      "Working on fill 7008\n",
      "Working on fill 7013\n",
      "Working on fill 7017\n",
      "Working on fill 7018\n",
      "Working on fill 7020\n",
      "Working on fill 7024\n",
      "Working on fill 7026\n",
      "Working on fill 7031\n",
      "Working on fill 7033\n",
      "Working on fill 7035\n",
      "Working on fill 7036\n",
      "Working on fill 7037\n",
      "#makeCycleDataFrame : Writing file [/eos/user/n/nkarast/LHC/2018/FollowUp/pickles/summaryEmittanceDataFrame_2018_periodB.pkl.gz]\n"
     ]
    }
   ],
   "source": [
    "outfilename   = output_folder+summary_filename\n",
    "# does the dataframe exists?\n",
    "df_exists = False\n",
    "if os.path.exists(outfilename):\n",
    "    print('[WARN] Filename of output file given for dataframe exists. Checking if it is up-to-date...')\n",
    "    df_exists = True\n",
    "    #df_old = pd.read_hdf(outfilename, 'df', format='table')\n",
    "    with gzip.open(outfilename, 'rb') as fid:\n",
    "        df_old = pickle.load(fid)\n",
    "    fills_existing = np.unique(df_old['Fill'].values)\n",
    "    overlap_fills = list(set(fills_existing.tolist()).intersection(flist))\n",
    "    print('[WARN] The old dataframe has already the fills : [{}] dropping them.'.format(overlap_fills))\n",
    "    newflist = [fil for fil in flist if fil not in overlap_fills]\n",
    "    flist = newflist\n",
    "    \n",
    "    if len(flist) == 0:\n",
    "        raise KeyboardInterrupt('[INFO] No new fills.') \n",
    "\n",
    "# Create the dataframe to store the loop items\n",
    "df_loop = pd.DataFrame() \n",
    "\n",
    "# Loop over the flist \n",
    "for filln in flist:\n",
    "    print('Working on fill {}'.format(filln))\n",
    "    \n",
    "    try:\n",
    "        # read cycle \n",
    "        with gzip.open('{}/fill_{}/fill_{}_cycle.pkl.gz'.format(input_folder, filln, filln), 'rb') as fid:\n",
    "            dcycle = pickle.load(fid)\n",
    "\n",
    "        with gzip.open('{}/fill_{}/fill_{}_cycle_model.pkl.gz'.format(input_folder, filln, filln), 'rb') as fid:\n",
    "            dmodel = pickle.load(fid)\n",
    "        with gzip.open('{}/fill_{}/fill_{}.pkl.gz'.format(input_folder, filln, filln), 'rb') as fid:\n",
    "            dsb = pickle.load(fid)\n",
    "    except:\n",
    "        print('--> Files for fill {} not found. Skipping it'.format(filln))\n",
    "        continue\n",
    "      \n",
    "    i_bunches = len(dsb['slots_filled_coll'][1])+len(dsb['slots_filled_noncoll'][1])\n",
    "  \n",
    "    \n",
    "    for nbeam in ['beam_1', 'beam_2']:\n",
    "        for cstep in ['Injection', 'he_before_SB']:\n",
    "            for tstep in ['at_start', 'at_end']:\n",
    "                for lplane in ['Horizontal', 'Vertical']:\n",
    "                    \n",
    "                    # keep a few lists for storing\n",
    "                    list_emit    = []\n",
    "                    list_time    = []\n",
    "                    list_cycle   = []\n",
    "                    list_slots   = []\n",
    "                    list_plane   = []\n",
    "                    list_beam    = []\n",
    "                    list_fill    = []\n",
    "                    list_bunches = []\n",
    "                    list_kind    = []\n",
    "\n",
    "                    list_intensity    = []\n",
    "                    list_bunch_length = []\n",
    "                    list_brightness   = []\n",
    "\n",
    "                    \n",
    "                    # fix string for Beam column\n",
    "                    if nbeam=='beam_1':\n",
    "                        i_beam = 'B1'\n",
    "                    elif nbeam=='beam_2':\n",
    "                        i_beam = 'B2'\n",
    "                    \n",
    "                    # fix string for plane column\n",
    "                    i_plane = lplane\n",
    "                    \n",
    "                    # get the correct emittance\n",
    "                    if lplane == 'Horizontal':\n",
    "                        emit_var = 'emith'\n",
    "                    elif lplane == 'Vertical':\n",
    "                        emit_var = 'emitv'\n",
    "                        \n",
    "                    # injection + at start / at end....\n",
    "                    if cstep == 'Injection' and tstep=='at_start':\n",
    "                        cycle_tag = 'Injection'\n",
    "                    elif cstep=='Injection' and tstep=='at_end':\n",
    "                        cycle_tag = 'Start Ramp'\n",
    "                    elif cstep=='he_before_SB' and tstep=='at_start':\n",
    "                        cycle_tag = 'End Ramp'\n",
    "                    elif cstep=='he_before_SB' and tstep=='at_end':\n",
    "                        cycle_tag = 'Start Stable'\n",
    "                    \n",
    "                    \n",
    "                    # measurements first\n",
    "                    list_emit.append(np.array(dcycle[nbeam][cstep][tstep][emit_var]))\n",
    "                    list_time.append(np.array(dcycle[nbeam][cstep][tstep]['time_meas']))\n",
    "                    list_slots.append(np.array(dcycle[nbeam][cstep]['filled_slots']))\n",
    "                    list_intensity.append(np.array(dcycle[nbeam][cstep][tstep]['intensity']))\n",
    "                    list_bunch_length.append(np.array(dcycle[nbeam][cstep][tstep]['blength']))\n",
    "                    list_brightness.append(np.array(dcycle[nbeam][cstep][tstep]['brightness']))\n",
    "                    list_cycle.append(np.array([cycle_tag]*len(np.array(dcycle[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_plane.append(np.array([lplane]*len(np.array(dcycle[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_beam.append(np.array([i_beam]*len(np.array(dcycle[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_fill.append(np.array([filln]*len(np.array(dcycle[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_bunches.append(np.array([i_bunches]*len(np.array(dcycle[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_kind.append(np.array(['Measurement']*len(np.array(dcycle[nbeam][cstep][tstep][emit_var]))))\n",
    "                    \n",
    "                    # now for the model\n",
    "                    list_emit.append(np.array(dmodel[nbeam][cstep][tstep][emit_var]))\n",
    "                    list_time.append(np.array(dmodel[nbeam][cstep][tstep]['time_meas']))\n",
    "                    list_slots.append(np.array(dmodel[nbeam][cstep]['filled_slots']))\n",
    "                    list_cycle.append(np.array([cycle_tag]*len(np.array(dmodel[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_plane.append(np.array([lplane]*len(np.array(dmodel[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_beam.append(np.array([i_beam]*len(np.array(dmodel[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_fill.append(np.array([filln]*len(np.array(dmodel[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_bunches.append(np.array([i_bunches]*len(np.array(dmodel[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_kind.append(np.array(['Model']*len(np.array(dmodel[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_intensity.append(np.array([np.nan]*len(np.array(dmodel[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_bunch_length.append(np.array([np.nan]*len(np.array(dmodel[nbeam][cstep][tstep][emit_var]))))\n",
    "                    list_brightness.append(np.array([np.nan]*len(np.array(dmodel[nbeam][cstep][tstep][emit_var]))))\n",
    "                                        \n",
    "                    # now convert stuff into lists:\n",
    "                    list_emit              = np.concatenate(list_emit).ravel().tolist()\n",
    "                    list_time              = np.concatenate(list_time).ravel().tolist()\n",
    "                    list_cycle             = np.concatenate(list_cycle).ravel().tolist()\n",
    "                    list_plane             = np.concatenate(list_plane).ravel().tolist()\n",
    "                    list_beam              = np.concatenate(list_beam).ravel().tolist()\n",
    "                    list_fill              = np.concatenate(list_fill).ravel().tolist()\n",
    "                    list_bunches           = np.concatenate(list_bunches).ravel().tolist()\n",
    "                    list_kind              = np.concatenate(list_kind).ravel().tolist()\n",
    "                    list_slots             = np.concatenate(list_slots).ravel().tolist()\n",
    "                    list_intensity         = np.concatenate(list_intensity).ravel().tolist()\n",
    "                    list_bunch_length      = np.concatenate(list_bunch_length).ravel().tolist()\n",
    "                    list_brightness        = np.concatenate(list_brightness).ravel().tolist()\n",
    "                    \n",
    "                    # create a temporary dataframe\n",
    "                    df_emit = pd.DataFrame()\n",
    "                    df_emit['Emittance']   = pd.Series(list_emit, dtype='float')\n",
    "                    df_emit['Intensity']   = pd.Series(list_intensity, dtype='float')\n",
    "                    df_emit['BunchLength'] = pd.Series(list_bunch_length, dtype='float')\n",
    "                    df_emit['Brightness']  = pd.Series(list_brightness, dtype='float')\n",
    "                    df_emit['Time']        = pd.Series(list_time, dtype='float')\n",
    "                    df_emit['Cycle']       = pd.Series(list_cycle, dtype='category')\n",
    "                    df_emit['Plane']       = pd.Series(list_plane, dtype='category')\n",
    "                    df_emit['Beam']        = pd.Series(list_beam, dtype='category')\n",
    "                    df_emit['Fill']        = pd.Series(list_fill, dtype='int')\n",
    "                    df_emit['Bunches']     = pd.Series(list_bunches, dtype='int')\n",
    "                    df_emit['Kind']        = pd.Series(list_kind, dtype='category')\n",
    "                    df_emit['Slot']        = pd.Series(list_slots, dtype='float')\n",
    "                    \n",
    "                    # append it into the total df\n",
    "                    df_loop = df_loop.append(df_emit, ignore_index=True)\n",
    "\n",
    "# this is the total dataframe:\n",
    "df_total = pd.DataFrame()\n",
    "if df_exists:\n",
    "    #df_old = pd.read_hdf(outfilename, 'df', format='table')\n",
    "    with gzip.open(outfilename,'rb') as fid:\n",
    "        df_old = pickle.load(fid)\n",
    "    df_total = df_old.append(df_loop, ignore_index=True)\n",
    "else:\n",
    "    df_total = df_loop\n",
    "\n",
    "################ WRITE THE TOTAL DF INTO A HDFS FILE #####################\n",
    "#df_total.to_hdf(outfilename, 'df', format='table')\n",
    "with gzip.open(outfilename, 'wb') as fid:\n",
    "    pickle.dump(df_total, fid)\n",
    "print('#makeCycleDataFrame : Writing file [{}]'.format(outfilename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create a dictionary that contains the total number of bunches\n",
    "\n",
    "This information is useful especially after the technical stops when the accelerator slowly ramps up and it also gives you some information on the dependency on the total intensity of the observed effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_bunches = pd.Series(df_total[['Fill','Bunches']].groupby('Fill').aggregate(np.mean)['Bunches'].values, index=df_total[['Fill','Bunches']].groupby('Fill').aggregate(np.mean).index).to_dict()\n",
    "\n",
    "def getBunches(x):\n",
    "    return dict_bunches[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "# Create a Growth DataFrame\n",
    "\n",
    "To ease up your life, the growth dataframe offers flattened information on the relative emittance blow up (or growth in um/h) between different steps of the LHC cycle:\n",
    "\n",
    "- INJ2FB : From INJECTION to start of RAMP (i.e. during Flat Bottom (FB))\n",
    "- FB2FT  : From Start of RAMP to end of RAMP (i.e. during RAMP)\n",
    "- FT2SB  : From the end of RAMP to the start of collisions (i.e. Flat Top (FT) before collisions)\n",
    "- INJ2SB : The total duration from INJECTION to Start of Stable Beams\n",
    "\n",
    "The dataframe includes both measured emittances as well as modelled emittances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf /eos/user/n/nkarast/LHC/2018/FollowUp/pickles/summaryEmittanceGrowthDataFrame_2018_periodB.pkl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "infilename = output_folder+summary_filename\n",
    "#df = pd.read_hdf(infilename, 'df', format='table')\n",
    "with gzip.open(infilename, 'rb') as fid:\n",
    "    df = pickle.load(fid)\n",
    "\n",
    "outfilename = output_folder + growth_filename\n",
    "\n",
    "# check if another growth file exists:\n",
    "growthDF_exists = False\n",
    "if os.path.exists(outfilename):\n",
    "    print('[WARN] Filename of output file given for growth dataframe exists. Checking if it is up-to-date...')\n",
    "    growthDF_exists = True\n",
    "    infilename = output_folder+growth_filename\n",
    "    #df_tmp_growth = pd.read_hdf(infilename, 'df', format='table')\n",
    "    with gzip.open(infilename, 'rb') as fid:\n",
    "        df_tmp_growth = pickle.load(fid)\n",
    "    fills_existing = np.unique(df_tmp_growth['Fill'].values)\n",
    "    fills_new = np.unique(df['Fill'].values)\n",
    "    overlap_fills = list(set(fills_existing.tolist()).intersection(fills_new.tolist()))\n",
    "    print('#[WARN] The old growth dataframe has already the fills : [{}] dropping them.'.format(overlap_fills))\n",
    "    df = df[~df['Fill'].isin(overlap_fills)]\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        raise KeyboardInterrupt('[WARN] No new fills to update DF. Exiting...') \n",
    "\n",
    "#########\n",
    "# split dataframe into measurements and model\n",
    "df_measure = df[(df['Kind']=='Measurement') & (~df['Fill'].isin(blacklist)) ]\n",
    "df_model   = df[(df['Kind']=='Model')       & (~df['Fill'].isin(blacklist)) ]\n",
    "\n",
    "\n",
    "# Total growth dataframe\n",
    "df_growth = pd.DataFrame()\n",
    "\n",
    "cycle_steps = ['Injection', 'Start Ramp', 'End Ramp', 'Start Stable']\n",
    "\n",
    "for i_cycle in range(len(cycle_steps)-1):\n",
    "    for i_beam in ['B1', 'B2']:\n",
    "        for i_plane in ['Horizontal', 'Vertical']:\n",
    "            \n",
    "            if cycle_steps[i_cycle] == 'Injection':\n",
    "                cycle_tag = 'INJ2FB'\n",
    "            elif cycle_steps[i_cycle] == 'Start Ramp':\n",
    "                cycle_tag = 'FB2FT'\n",
    "            elif cycle_steps[i_cycle] == 'End Ramp':\n",
    "                cycle_tag = 'FT2SB'           \n",
    "            \n",
    "            # create a local copy of the measured dfs\n",
    "            tmp_df_measure1 = df_measure[(df_measure['Beam']==i_beam) & (df_measure['Plane']==i_plane)& (df_measure['Cycle']==cycle_steps[i_cycle])].copy()\n",
    "            tmp_df_measure2 = df_measure[(df_measure['Beam']==i_beam) & (df_measure['Plane']==i_plane)& (df_measure['Cycle']==cycle_steps[i_cycle+1])].copy()\n",
    "            \n",
    "            dt_meas         = tmp_df_measure2['Time'].values             - tmp_df_measure1['Time'].values\n",
    "            demit_meas      = tmp_df_measure2['Emittance'].values        - tmp_df_measure1['Emittance'].values\n",
    "            demit_rel_meas  = ((tmp_df_measure2['Emittance'].values      - tmp_df_measure1['Emittance'].values)/(tmp_df_measure1['Emittance'].values))*100.\n",
    "            growth_meas     = 3600.*(tmp_df_measure2['Emittance'].values - tmp_df_measure1['Emittance'].values)/dt_meas\n",
    "\n",
    "            \n",
    "            \n",
    "            # create a local copy of the model dfs\n",
    "            tmp_df_model1   = df_model[(df_model['Beam']==i_beam) & (df_model['Plane']==i_plane)& (df_model['Cycle']==cycle_steps[i_cycle])].copy()\n",
    "            tmp_df_model2   = df_model[(df_model['Beam']==i_beam) & (df_model['Plane']==i_plane)& (df_model['Cycle']==cycle_steps[i_cycle+1])].copy()\n",
    "            \n",
    "            dt_model        = tmp_df_model2['Time'].values             - tmp_df_model1['Time'].values\n",
    "            demit_model     = tmp_df_model2['Emittance'].values        - tmp_df_model1['Emittance'].values\n",
    "            demit_rel_model = ((tmp_df_model2['Emittance'].values      - tmp_df_model1['Emittance'].values)/(tmp_df_model1['Emittance'].values))*100.\n",
    "            growth_model    = 3600.*(tmp_df_model2['Emittance'].values - tmp_df_model1['Emittance'].values)/dt_model\n",
    "\n",
    "            \n",
    "            df_tmp = pd.DataFrame()\n",
    "            df_tmp['Fill']                           = tmp_df_measure1['Fill'] #[i_plane]*len(df_tmp)\n",
    "            df_tmp['Beam']                           = tmp_df_measure1['Beam'] #[i_beam]*len(df_tmp)\n",
    "            df_tmp['Plane']                          = tmp_df_measure1['Plane'] #[i_plane]*len(df_tmp)\n",
    "            df_tmp['Cycle']                          = [cycle_tag]*len(df_tmp)\n",
    "            df_tmp['Slot']                           = tmp_df_measure1['Slot']\n",
    "            df_tmp['MeasuredDeltaEmittance']         = demit_meas\n",
    "            df_tmp['MeasuredDt']                     = dt_meas\n",
    "            df_tmp['MeasuredRelativeDeltaEmittance'] = demit_rel_meas\n",
    "            df_tmp['MeasuredEmittanceGrowth']        = growth_meas\n",
    "            df_tmp['ModelDeltaEmittance']            = demit_model\n",
    "            df_tmp['ModelDt']                        = dt_model\n",
    "            df_tmp['ModelRelativeDeltaEmittance']    = demit_rel_model\n",
    "            df_tmp['ModelEmittanceGrowth']           = growth_model\n",
    "                        \n",
    "            df_growth = df_growth.append(df_tmp, ignore_index=True)\n",
    "            \n",
    "##### CREATE THE INJ2SB PART:\n",
    "for i_beam in ['B1', 'B2']:\n",
    "    for i_plane in ['Horizontal', 'Vertical']:\n",
    "\n",
    "        cycle_tag = 'INJ2SB'\n",
    "\n",
    "        # create a local copy of the measured dfs\n",
    "        tmp_df_measure1  = df_measure[(df_measure['Beam']==i_beam) & (df_measure['Plane']==i_plane)& (df_measure['Cycle']=='Injection')].copy()\n",
    "        tmp_df_measure2  = df_measure[(df_measure['Beam']==i_beam) & (df_measure['Plane']==i_plane)& (df_measure['Cycle']=='Start Stable')].copy()\n",
    "\n",
    "        dt_meas          = tmp_df_measure2['Time'].values             - tmp_df_measure1['Time'].values\n",
    "        demit_meas       = tmp_df_measure2['Emittance'].values        - tmp_df_measure1['Emittance'].values\n",
    "        demit_rel_meas   = ((tmp_df_measure2['Emittance'].values      - tmp_df_measure1['Emittance'].values)/(tmp_df_measure1['Emittance'].values))*100.\n",
    "        growth_meas      = 3600.*(tmp_df_measure2['Emittance'].values - tmp_df_measure1['Emittance'].values)/dt_meas\n",
    "        bunches_meas     = tmp_df_measure2['Bunches']\n",
    "\n",
    "\n",
    "        # create a local copy of the model dfs\n",
    "        tmp_df_model1    = df_model[(df_model['Beam']==i_beam) & (df_model['Plane']==i_plane)& (df_model['Cycle']=='Injection')].copy()\n",
    "        tmp_df_model2    = df_model[(df_model['Beam']==i_beam) & (df_model['Plane']==i_plane)& (df_model['Cycle']=='Start Stable')].copy()\n",
    "\n",
    "        dt_model         = tmp_df_model2['Time'].values             - tmp_df_model1['Time'].values\n",
    "        demit_model      = tmp_df_model2['Emittance'].values        - tmp_df_model1['Emittance'].values\n",
    "        demit_rel_model  = ((tmp_df_model2['Emittance'].values      - tmp_df_model1['Emittance'].values)/(tmp_df_model1['Emittance'].values))*100.\n",
    "        growth_model     = 3600.*(tmp_df_model2['Emittance'].values - tmp_df_model1['Emittance'].values)/dt_model\n",
    "\n",
    "\n",
    "        df_tmp = pd.DataFrame()\n",
    "        df_tmp['Fill']                           = tmp_df_measure1['Fill'] #[i_plane]*len(df_tmp)\n",
    "        df_tmp['Beam']                           = tmp_df_measure1['Beam'] #[i_beam]*len(df_tmp)\n",
    "        df_tmp['Plane']                          = tmp_df_measure1['Plane'] #[i_plane]*len(df_tmp)\n",
    "        df_tmp['Cycle']                          = [cycle_tag]*len(df_tmp)\n",
    "        df_tmp['Slot']                           = tmp_df_measure1['Slot']\n",
    "\n",
    "        df_tmp['MeasuredDeltaEmittance']         = demit_meas\n",
    "        df_tmp['MeasuredDt']                     = dt_meas\n",
    "        df_tmp['MeasuredRelativeDeltaEmittance'] = demit_rel_meas\n",
    "        df_tmp['MeasuredEmittanceGrowth']        = growth_meas\n",
    "\n",
    "        df_tmp['ModelDeltaEmittance']            = demit_model\n",
    "        df_tmp['ModelDt']                        = dt_model\n",
    "        df_tmp['ModelRelativeDeltaEmittance']    = demit_rel_model\n",
    "        df_tmp['ModelEmittanceGrowth']           = growth_model\n",
    "\n",
    "        df_growth = df_growth.append(df_tmp, ignore_index=True)\n",
    "        df_growth['Bunches'] = df_growth['Fill'].apply(lambda x: getBunches(x))\n",
    "\n",
    "# kill all nan/inf \n",
    "df_growth = df_growth.replace([np.inf, -np.inf], np.nan)\n",
    "df_growth = df_growth[df_growth['MeasuredDt']>=5.0*60].dropna(axis=0, how='any')\n",
    "\n",
    "\n",
    "# save\n",
    "#df_growth.to_hdf(outfilename, 'df', format='table')\n",
    "if growthDF_exists:\n",
    "    with gzip.open(outfilename, \"rb\") as fid:\n",
    "        df_growth_old = pickle.load(fid)\n",
    "    df_growth_total = df_growth_old.append(df_growth, ignore_index=True)\n",
    "    df_growth = df_growth_total\n",
    "\n",
    "with gzip.open(outfilename, 'wb') as fid:\n",
    "    pickle.dump(df_growth, fid)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

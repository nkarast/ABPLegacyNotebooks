{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collections of functions to be used as init script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/eos/user/n/nkarast/myLibrary/init.ipynb :: Ignoring warnings.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import time\n",
    "import matplotlib\n",
    "from colorsys import hsv_to_rgb\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter, MaxNLocator\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.dates as md\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import sympy as sp\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "from pprint import pprint\n",
    "import pytz\n",
    "from scipy.signal import savgol_filter\n",
    "from operator import itemgetter\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import cl2pd\n",
    "from cl2pd import importData\n",
    "from cl2pd import plotFunctions\n",
    "from cl2pd import dotdict\n",
    "from cl2pd import bbFunctions\n",
    "from cl2pd import variablesDF\n",
    "cals=importData.cals\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print('/eos/user/n/nkarast/myLibrary/init.ipynb :: Ignoring warnings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `u'/eos/user/n/nkarast/myLibrary/resonanceLines.ipynb.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run -i ~/myLibrary/resonanceLines.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_timezone = pytz.timezone(\"Europe/Zurich\")\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "plt.rcParams['axes.labelsize']   = 18\n",
    "plt.rcParams['axes.labelweight'] = 'normal'\n",
    "plt.rcParams['xtick.labelsize']  = 16\n",
    "plt.rcParams['ytick.labelsize']  = 16\n",
    "plt.rcParams['legend.fontsize']  = 16\n",
    "plt.rcParams['figure.titlesize'] = 20\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "get_ipython().magic('matplotlib inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the functions begin..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setJupyterWidth():\n",
    "    '''Sets Jupyter Notebook width to 100% via HTML'''\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertNumpyToTimestamp(x):\n",
    "    '''converts numpy to timestamp'''\n",
    "    try:\n",
    "        return pd.DatetimeIndex(x)[0]\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilledSlotsArray(dict_intervals_two_beams, beam, cycle, cycleTime,  mask_invalid=True):\n",
    "    '''\n",
    "    Returns the array with the filled slots.\n",
    "    Inputs : beam           : beam string ('beam_1', 'beam_2')\n",
    "             cycle          : cycle string ('injection', 'flattop')\n",
    "             cycleTime      : cycle step string ('injection_start', 'injection_end', 'flattop_start', 'flattop_end')\n",
    "             mask_invalid   : boolean True/False to mask invalid values in the output array\n",
    "    Returns: filled_slots array\n",
    "    '''\n",
    "    return ma.masked_invalid(dict_intervals_two_beams[beam][cycle]['filled_slots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToLocalTime(df_timeRange, timezone=\"Europe/Zurich\", scalar=False):\n",
    "    '''\n",
    "    Converts a Series (Pandas Column) in Local Time and returns it.\n",
    "    Input  : df_timeRange : Pandas Series with timestamp data\n",
    "             timezone     : timezone (tz) string - defaults to Europe/Zurich\n",
    "             scalar \t  : if it is a single value and not list/array\n",
    "    Returns: converted pandas Series\n",
    "    '''\n",
    "    if isinstance(df_timeRange, list) or isinstance(df_timeRange, np.ndarray) or isinstance(df_timeRange, pd.core.series.Series):\n",
    "        return np.array(pd.to_datetime(np.array(df_timeRange), unit='s', utc=True).tz_convert(timezone).tz_localize(None))\n",
    "    else:\n",
    "        return datetime.datetime.utcfromtimestamp(df_timeRange) + (datetime.datetime.now()-datetime.datetime.utcnow()) # + utc offset to fix local zone\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_and_spread(axc, x_vect, ymat, color = 'k', alpha=1, label=None, shade=False):\n",
    "    '''\n",
    "    Function to plot the average value and the +/- 2sigma range of a given\n",
    "    vector on a given axis\n",
    "\n",
    "    Inputs : axc : axis on which you want me to plot stuff\n",
    "             x_vect: array of x-axis values (any iterable object)\n",
    "             y_mat : array of y-axis values for which the std and mean will be Calculated\n",
    "             color : the color for the lines\n",
    "             alpha : the alpha of the lines\n",
    "             label : label to add to this axis\n",
    "             shade : plot in shade the +/- 1 standard deviation band\n",
    "    Returns: None -- simply adds stuff on the given pl.axis\n",
    "    '''\n",
    "    avg = np.nanmean(ymat, axis=1)\n",
    "    std = np.nanstd(ymat, axis=1)\n",
    "\n",
    "    if shade:\n",
    "        axc.fill_between(x_vect, avg-std, avg+std, alpha=.3, color=color, label=None)\n",
    "    else:\n",
    "        axc.plot(x_vect, avg-1*std, '--', color=color, linewidth=1, alpha=alpha, label=None)\n",
    "        axc.plot(x_vect, avg+1*std, '--', color=color, linewidth=1, alpha=alpha, label=None)\n",
    "        axc.plot(x_vect, avg, color=color, linewidth=2, alpha=alpha, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorprog(i_prog, Nplots, v1 = .9, v2 = 1.):\n",
    "    '''\n",
    "    Function to return different colors for bunch plots\n",
    "    '''\n",
    "    if hasattr(Nplots, '__len__'):\n",
    "        Nplots = len(Nplots)\n",
    "    return hsv_to_rgb(float(i_prog)/float(Nplots), v1, v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLHCSuperTable(fill_min=None, fill_max=None, t1=None, t2=None):\n",
    "    '''\n",
    "    Returns a \"SuperTable\" for fills within fill_min, fill_max or in time range t1,t2\n",
    "    '''\n",
    "    st_vars = ['LHC.STATS:FILL_NUMBER', 'LHC.STATS:ENERGY', 'LHC.STATS:LHC:INJECTION_SCHEME', 'LHC.STATS:B1_NUMBER_BUNCHES', 'LHC.STATS:NUMBER_COLLISIONS_IP1_5', 'LHC.STATS:NUMBER_COLLISIONS_IP2', 'LHC.STATS:NUMBER_COLLISIONS_IP8',\n",
    "               'LHC.STATS:BETA_STAR_ALICE', 'LHC.STATS:BETA_STAR_ATLAS', 'LHC.STATS:BETA_STAR_CMS', 'LHC.STATS:BETA_STAR_LHCB',  'LHC.STATS:LUMI_ATLAS_DELIVERED', 'LHC.STATS:LUMI_ATLAS_PEAK', 'LHC.STATS:LUMI_CMS_DELIVERED', 'LHC.STATS:LUMI_CMS_PEAK',\n",
    "               'LHC.STATS:LHCB_HALF_CROSSING_ANGLE', 'LHC.STATS:ALICE_HALF_CROSSING_ANGLE', 'LHC.STATS:ATLAS_HALF_CROSSING_ANGLE', 'LHC.STATS:CMS_HALF_CROSSING_ANGLE', \n",
    "               'LHC.STATS:SPS_H_ROT_IN:EMITTANCE', 'LHC.STATS:SPS_V_ROT_IN:EMITTANCE']\n",
    "    \n",
    "    if fill_min is not None and fill_max is not None and t1 is None and t2 is None:\n",
    "        print \"Running SuperTable by fills [{}, {}]...\".format(fill_min, fill_max)\n",
    "        log = pytimber.LoggingDB()\n",
    "        d1 = log.getLHCFillData(fill_min, True)\n",
    "        t1 = convertToLocalTime(d1['startTime'])\n",
    "        d2 = log.getLHCFillData(fill_max, True)\n",
    "        t2 = convertToLocalTime(d2['endTime'])\n",
    "        print \"Corresponding start/end time is : [{}, {}]\".format(t1, t2)\n",
    "    elif fill_min is None and fill_max is None and t1 is not None and t2 is not None:\n",
    "        print \"Running SuperTable by time [{},{}]...\".format(t1, t2)\n",
    "    else:\n",
    "        print \"Getting SuperTable for the last five days...\"\n",
    "        t1 = datetime.datetime.now() - datetime.timedelta(days=5)\n",
    "        t2 = datetime.datetime.now()\n",
    "        \n",
    "    df = myToolbox.cals2pnd(st_vars, t1,t2)\n",
    "    df.columns = [x.split('LHC.STATS:')[1] for x in df.columns.tolist()]\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    return df.set_index(['FILL_NUMBER'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertNumpyDatetimeToDatetime(times):\n",
    "    '''\n",
    "    converts the np.datetime64 to datetime.datetime at local time\n",
    "    returns an array object\n",
    "    '''\n",
    "    result = np.array([x.replace(tzinfo=pytz.utc).astimezone(_timezone) for x in map(datetime.datetime.utcfromtimestamp, times.astype(np.int64)/1e9)])\n",
    "    if len(result)==1:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pp():\n",
    "    \"This an auxillary class to allow for LaTeX output between subsequent derivation steps.\"\n",
    "    def __init__(self, eq, left=None):\n",
    "        self.eq = eq\n",
    "        self.left = left\n",
    "    def _repr_html_(self):\n",
    "        if self.left:\n",
    "            return \"$\" + sp.latex(self.left) + \" = \" + sp.latex(self.eq) + \"$\"\n",
    "        return \"$\" + sp.latex(self.eq) + \"$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printBSRTCalibrationFactor(filln):\n",
    "    '''given a fill prints out the calibration factors (mean over FB/FT)'''\n",
    "    tf1, tf2 = getLHCFillTimes(filln)\n",
    "    fills, bmodes = myToolbox.LHCFillsByTime2pnd(tf1, tf2)\n",
    "    \n",
    "    t_start_inj   = bmodes['startTime'][bmodes['mode']=='INJPHYS'].values[0]\n",
    "    t_start_ramp  = bmodes['endTime'][bmodes['mode']=='PRERAMP'].values[0]\n",
    "    t_start_ft    = bmodes['startTime'][bmodes['mode']=='FLATTOP'].values[0]\n",
    "    t_end_sb      = bmodes['endTime'][bmodes['mode']=='STABLE'].values[0]\n",
    "    \n",
    "    dt_start_inj  = datetime.datetime.utcfromtimestamp(t_start_inj.tolist()/1e9)\n",
    "    dt_start_ramp = datetime.datetime.utcfromtimestamp(t_start_ramp.tolist()/1e9)\n",
    "    dt_start_ft   = datetime.datetime.utcfromtimestamp(t_start_ft.tolist()/1e9)\n",
    "    dt_end_sb     = datetime.datetime.utcfromtimestamp(t_end_sb.tolist()/1e9)\n",
    "    \n",
    "    beam_vars = { 1:['LHC.BSRT.5R4.B1:BETA_H', \n",
    "                      'LHC.BSRT.5R4.B1:BETA_V', \n",
    "                      'LHC.BSRT.5R4.B1:SCALE_H', \n",
    "                      'LHC.BSRT.5R4.B1:SCALE_V', \n",
    "                      'LHC.BSRT.5R4.B1:LSF_H', \n",
    "                      'LHC.BSRT.5R4.B1:LSF_V', \n",
    "              ],\n",
    "\n",
    "             2: [ 'LHC.BSRT.5L4.B2:BETA_H', \n",
    "                  'LHC.BSRT.5L4.B2:BETA_V', \n",
    "                  'LHC.BSRT.5L4.B2:SCALE_H', \n",
    "                  'LHC.BSRT.5L4.B2:SCALE_V', \n",
    "                  'LHC.BSRT.5L4.B2:LSF_H', \n",
    "                  'LHC.BSRT.5L4.B2:LSF_V', \n",
    "              ],\n",
    "            }\n",
    "    dfs = {1: {'FB': None, 'FT': None},\n",
    "           2: {'FB': None, 'FT': None}}\n",
    "    for beam_n in [1,2]:\n",
    "        for tag in ['FB', 'FT']:\n",
    "            print(\"Working on beam-{} {}\".format(beam_n, tag))\n",
    "            tmp_vars = beam_vars[beam_n]\n",
    "            tmp_df = pd.DataFrame()\n",
    "\n",
    "            if tag == 'FB':\n",
    "                t1 = dt_start_inj\n",
    "                t2 = dt_start_ramp\n",
    "            elif tag == 'FT':\n",
    "                t1 = dt_start_ft\n",
    "                t2 = dt_end_sb\n",
    "\n",
    "            tmp_df = myToolbox.cals2pnd(tmp_vars, t1, t2)\n",
    "            dfs[beam_n][tag]=tmp_df\n",
    "    print('''\n",
    "            for kk in e_dict.keys():\n",
    "                e_dict[kk] = {450:{}, 6500:{}}'''+'''\n",
    "            \n",
    "            e_dict['betaf_h'][450][1]       = {}\n",
    "            e_dict['betaf_h'][6500][1]      = {}\n",
    "                \n",
    "            e_dict['betaf_v'][450][1]       = {}\n",
    "            e_dict['betaf_v'][6500][1]      = {}\n",
    "                \n",
    "            e_dict['sigma_corr_h'][450][1]  = {}\n",
    "            e_dict['sigma_corr_h'][6500][1] = {}\n",
    "                \n",
    "            e_dict['sigma_corr_v'][450][1]  = {}\n",
    "            e_dict['sigma_corr_v'][6500][1] = {}\n",
    "                \n",
    "            e_dict['scale_h'][450][1]       = {}\n",
    "            e_dict['scale_h'][6500][1]      = {}\n",
    "                \n",
    "            e_dict['scale_v'][450][1]       = {}\n",
    "            e_dict['scale_v'][6500][1]      = {}\n",
    "                \n",
    "            e_dict['rescale_sigma_h'][450][1]  = 1.\n",
    "            e_dict['rescale_sigma_h'][6500][1] = 1.\n",
    "            e_dict['rescale_sigma_v'][450][1]  = 1.\n",
    "            e_dict['rescale_sigma_v'][6500][1] = 1.\n",
    "                \n",
    "            # Beam 2:\n",
    "            e_dict['betaf_h'][450][2]       = {}\n",
    "            e_dict['betaf_h'][6500][2]      = {}\n",
    "                \n",
    "            e_dict['betaf_v'][450][2]       = {}\n",
    "            e_dict['betaf_v'][6500][2]      = {}\n",
    "                \n",
    "            e_dict['sigma_corr_h'][450][2]  = {}\n",
    "            e_dict['sigma_corr_h'][6500][2] = {}\n",
    "                \n",
    "            e_dict['sigma_corr_v'][450][2]  = {}\n",
    "            e_dict['sigma_corr_v'][6500][2] = {}\n",
    "                \n",
    "            e_dict['scale_h'][450][2]       = {}\n",
    "            e_dict['scale_h'][6500][2]      = {}\n",
    "                \n",
    "            e_dict['scale_v'][450][2]       = {}\n",
    "            e_dict['scale_v'][6500][2]      = {}\n",
    "                \n",
    "            e_dict['rescale_sigma_h'][450][2]  = 1.\n",
    "            e_dict['rescale_sigma_h'][6500][2] = 1.\n",
    "            e_dict['rescale_sigma_v'][450][2]  = 1.\n",
    "            e_dict['rescale_sigma_v'][6500][2] = 1.\n",
    "            \n",
    "            # gamma\n",
    "            e_dict['gamma'][450] = 479.6\n",
    "            e_dict['gamma'][6500] = 6927.6\n",
    "\n",
    "            print('Using calibration TEST')\n",
    "                '''.format(dfs[1]['FB']['LHC.BSRT.5R4.B1:BETA_H'].mean(), \n",
    "                           dfs[1]['FT']['LHC.BSRT.5R4.B1:BETA_H'].mean(), \n",
    "                           dfs[1]['FB']['LHC.BSRT.5R4.B1:BETA_V'].mean(), \n",
    "                           dfs[1]['FT']['LHC.BSRT.5R4.B1:BETA_V'].mean(), \n",
    "                           dfs[1]['FB']['LHC.BSRT.5R4.B1:LSF_H'].mean(), \n",
    "                           dfs[1]['FT']['LHC.BSRT.5R4.B1:LSF_H'].mean(), \n",
    "                           dfs[1]['FB']['LHC.BSRT.5R4.B1:LSF_V'].mean(), \n",
    "                           dfs[1]['FT']['LHC.BSRT.5R4.B1:LSF_V'].mean(), \n",
    "                           dfs[1]['FB']['LHC.BSRT.5R4.B1:SCALE_H'].mean(), \n",
    "                           dfs[1]['FT']['LHC.BSRT.5R4.B1:SCALE_H'].mean(), \n",
    "                           dfs[1]['FB']['LHC.BSRT.5R4.B1:SCALE_V'].mean(), \n",
    "                           dfs[1]['FT']['LHC.BSRT.5R4.B1:SCALE_V'].mean(), \n",
    "                           dfs[2]['FB']['LHC.BSRT.5L4.B2:BETA_H'].mean(), \n",
    "                           dfs[2]['FT']['LHC.BSRT.5L4.B2:BETA_H'].mean(), \n",
    "                           dfs[2]['FB']['LHC.BSRT.5L4.B2:BETA_V'].mean(), \n",
    "                           dfs[2]['FT']['LHC.BSRT.5L4.B2:BETA_V'].mean(), \n",
    "                           dfs[2]['FB']['LHC.BSRT.5L4.B2:LSF_H'].mean(), \n",
    "                           dfs[2]['FT']['LHC.BSRT.5L4.B2:LSF_H'].mean(), \n",
    "                           dfs[2]['FB']['LHC.BSRT.5L4.B2:LSF_V'].mean(), \n",
    "                           dfs[2]['FT']['LHC.BSRT.5L4.B2:LSF_V'].mean(), \n",
    "                           dfs[2]['FB']['LHC.BSRT.5L4.B2:SCALE_H'].mean(), \n",
    "                           dfs[2]['FT']['LHC.BSRT.5L4.B2:SCALE_H'].mean(), \n",
    "                           dfs[2]['FB']['LHC.BSRT.5L4.B2:SCALE_V'].mean(), \n",
    "                           dfs[2]['FT']['LHC.BSRT.5L4.B2:SCALE_V'].mean()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFillingScheme(filln):\n",
    "    '''Given a fill number return:\n",
    "    filled_slots_b1, filled_slots_b2, slots_coll_b1, slots_coll_b2, slots_noncoll_b1, slots_noncoll_b2, b1_fill_pattern, b2_fill_pattern\n",
    "    '''\n",
    "    \n",
    "    bmodes = importData.LHCFillsByNumber(filln)\n",
    "    FILL_PATTERN_DF = pd.DataFrame()\n",
    "    FILL_PATTERN_DF = importData.cals2pd(['LHC.BCTFR.A6R4.B1:BUNCH_FILL_PATTERN','LHC.BCTFR.A6R4.B2:BUNCH_FILL_PATTERN'], pd.Timestamp(bmodes['startTime'][bmodes['mode']=='PRERAMP'].values[0]), pd.Timestamp(bmodes['startTime'][bmodes['mode']=='PRERAMP'].values[0]+pd.Timedelta(seconds=1)) )\n",
    "    b1_fill_pattern = np.array(FILL_PATTERN_DF.filter(regex=\"LHC.*B1.*\").iloc[0].values[0]);\n",
    "    b2_fill_pattern = np.array(FILL_PATTERN_DF.filter(regex=\"LHC.*B2.*\").iloc[0].values[0]);\n",
    "\n",
    "    # define the filled slots and the colliding / non-colliding\n",
    "    filled_slots_b1 = np.where(b1_fill_pattern == 1)[0]\n",
    "    filled_slots_b2 = np.where(b2_fill_pattern == 1)[0]\n",
    "    slots_noncoll_b1 = np.array([x for x in filled_slots_b1 if x not in filled_slots_b2])\n",
    "    slots_noncoll_b2 = np.array([x for x in filled_slots_b2 if x not in filled_slots_b1])\n",
    "    slots_coll_b1 = np.array([x for x in filled_slots_b1 if x in filled_slots_b2])\n",
    "    slots_coll_b2 = np.array([x for x in filled_slots_b2 if x in filled_slots_b1])\n",
    "\n",
    "    print('---------- FILL {} ----------'.format(filln))\n",
    "    print('B1 slots               : {}'.format(len(filled_slots_b1)))\n",
    "    print('B2 slots               : {}'.format(len(filled_slots_b2)))\n",
    "    print('B1 colliding slots     : {}'.format(len(slots_coll_b1)))\n",
    "    print('B2 colliding slots     : {}'.format(len(slots_coll_b2)))\n",
    "    print('B1 non-colliding slots : {}'.format(len(slots_noncoll_b1)))\n",
    "    print('B2 non-colliding slots : {}'.format(len(slots_noncoll_b2)))\n",
    "    return filled_slots_b1, filled_slots_b2, slots_coll_b1, slots_coll_b2, slots_noncoll_b1, slots_noncoll_b2, b1_fill_pattern, b2_fill_pattern\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFillingScheme(filln):\n",
    "    filled_slots_b1, filled_slots_b2, slots_coll_b1, slots_coll_b2, slots_noncoll_b1, slots_noncoll_b2, b1_fill_pattern, b2_fill_pattern = getFillingScheme(filln)\n",
    "    fig1 = plt.figure('fillPattern', figsize=(12,9))\n",
    "    ax1 = plt.subplot(211)       \n",
    "    ax1.step(np.arange(len(b1_fill_pattern)), b1_fill_pattern, where='post', color='b', lw=2);\n",
    "    plt.yticks([0,1], ['EMPTY', 'FILLED']);\n",
    "    ax1.set_xlim(-100, 3570);\n",
    "    ax1.set_ylim(0, 1.1);\n",
    "    ax1.set_ylabel('BEAM 1', fontsize=18);\n",
    "    ax1.set_title('FILL {}'.format(filln), fontsize=20);\n",
    "    \n",
    "    \n",
    "    # -- beam 2\n",
    "    ax2 = plt.subplot(212, sharex=ax1, sharey=ax1);\n",
    "    ax2.step(np.arange(len(b2_fill_pattern)), b2_fill_pattern, where='post', color='r', lw=2);\n",
    "    ax2.set_ylabel('BEAM 2', fontsize=18);\n",
    "    plt.yticks([0,1], ['EMPTY', 'FILLED']);\n",
    "    ax2.set_xlabel('Bunch Slot [25ns]', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBeamBatches(filln):\n",
    "    '''Given a fill number, aquire the filling pattern and return a list of lists for b1_trains, b2_trains'''\n",
    "    filled_slots_b1, filled_slots_b2, slots_coll_b1, slots_coll_b2, slots_noncoll_b1, slots_noncoll_b2, b1_fill_pattern, b2_fill_pattern = getFillingScheme(filln)\n",
    "    b1_trains, b2_trains = [], []\n",
    "    for k,g in itertools.groupby(enumerate(filled_slots_b1),lambda x:x[0]-x[1]):\n",
    "        group = (map(itemgetter(1),g))\n",
    "        group = list(map(int,group))\n",
    "        b1_trains.append(group)\n",
    "    for k,g in itertools.groupby(enumerate(filled_slots_b2),lambda x:x[0]-x[1]):\n",
    "        group = (map(itemgetter(1),g))\n",
    "        group = list(map(int,group))\n",
    "        b2_trains.append(group)#ranges.append((group[0],group[-1]))\n",
    "        \n",
    "    return b1_trains, b2_trains\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewColor(nmax):\n",
    "    '''given: nmax, n (maximum length and current id) return a new color to be used in loop'''\n",
    "    color=iter(plt.cm.rainbow(np.linspace(0,1,nmax)))\n",
    "    colors = []\n",
    "    for i in xrange(nmax):\n",
    "        c=next(color)\n",
    "        colors.append(c)\n",
    "        \n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatDatetimeAxis(ax, which='x', fmt=\"%H:%M\"):\n",
    "    '''Sets the format datetime axis of (ax) of (which=x|y|both) axis to fmt (\"%H:%M\")\n",
    "    '''\n",
    "    if which=='x':\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(fmt))\n",
    "    elif which == 'y':\n",
    "        ax.yaxis.set_major_formatter(mdates.DateFormatter(fmt))\n",
    "    elif which =='both':\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(fmt))\n",
    "        ax.yaxis.set_major_formatter(mdates.DateFormatter(fmt))\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setAxisMaxLocator(ax, which='y', nloc=10):\n",
    "    '''Sets the maxlocator of (ax) of (which=x|y|both) axis to nloc (10)\n",
    "    '''\n",
    "    if which=='y':\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(nloc))\n",
    "    elif which=='x':\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(nloc))\n",
    "    elif which=='both':\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(nloc))\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(nloc))\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEncounterSchedule(filln, nInsideD1=5, nLR=[16, 16, 15]):\n",
    "    '''\n",
    "    Returns the encounter pattern:\n",
    "    ndf_b1, ndf_b2 = collision schedules for b1, b2\n",
    "    '''\n",
    "    filled_slots_b1, filled_slots_b2, slots_coll_b1, slots_coll_b2, slots_noncoll_b1, slots_noncoll_b2, b1_fill_pattern, b2_fill_pattern = getFillingScheme(filln)\n",
    "    BBMATRIX = bbFunctions.computeBBMatrix(nLR)\n",
    "    b1_collisionScheduleDF = bbFunctions.B1CollisionScheduleDF(b1_fill_pattern, b2_fill_pattern, nLR)\n",
    "    b2_collisionScheduleDF = bbFunctions.B2CollisionScheduleDF(b1_fill_pattern, b2_fill_pattern, nLR)\n",
    "    bbencounters = bbFunctions.BBEncounterSchedule(filled_slots_b1, filled_slots_b2, BBMATRIX)\n",
    "    \n",
    "\n",
    "    # Collides in IP2\n",
    "    # -- B1\n",
    "    b1_collisionScheduleDF['collidesIP2'] = b1_collisionScheduleDF[\"HO partner in ALICE\"].fillna(-1)\n",
    "    b1_collisionScheduleDF['collidesIP2'][b1_collisionScheduleDF['collidesIP2']>=0] = 2\n",
    "    # -- B2\n",
    "    b2_collisionScheduleDF['collidesIP2'] = b2_collisionScheduleDF[\"HO partner in ALICE\"].fillna(-1)\n",
    "    b2_collisionScheduleDF['collidesIP2'][b2_collisionScheduleDF['collidesIP2']>=0] = 2\n",
    "\n",
    "    # Collides in IP8\n",
    "    # -- B1\n",
    "    b1_collisionScheduleDF['collidesIP8'] = b1_collisionScheduleDF[\"HO partner in LHCB\"].fillna(-1)\n",
    "    b1_collisionScheduleDF['collidesIP8'][b1_collisionScheduleDF['collidesIP8']>=0] = 3\n",
    "    # -- B2\n",
    "    b2_collisionScheduleDF['collidesIP8'] = b2_collisionScheduleDF[\"HO partner in LHCB\"].fillna(-1)\n",
    "    b2_collisionScheduleDF['collidesIP8'][b2_collisionScheduleDF['collidesIP8']>=0] = 3\n",
    "\n",
    "    # Collides in IP1/5\n",
    "    # -- B1\n",
    "    b1_collisionScheduleDF['collidesIP1'] = b1_collisionScheduleDF[\"HO partner in ATLAS/CMS\"].fillna(-1)\n",
    "    b1_collisionScheduleDF['collidesIP1'][b1_collisionScheduleDF['collidesIP1']>=0] = 1\n",
    "    # -- B2\n",
    "    b2_collisionScheduleDF['collidesIP1'] = b2_collisionScheduleDF[\"HO partner in ATLAS/CMS\"].fillna(-1)\n",
    "    b2_collisionScheduleDF['collidesIP1'][b2_collisionScheduleDF['collidesIP1']>=0] = 1\n",
    "    \n",
    "    ndf_b1 = pd.DataFrame()\n",
    "    ndf_b2 = pd.DataFrame()\n",
    "    \n",
    "    ndf_b1['IP15'] = b1_collisionScheduleDF['# of LR in ATLAS/CMS']\n",
    "    ndf_b1['IP2']  = b1_collisionScheduleDF['# of LR in ALICE']\n",
    "    ndf_b1['IP8']  = b1_collisionScheduleDF['# of LR in LHCB']\n",
    "    ndf_b1.index   = b1_collisionScheduleDF.index\n",
    "\n",
    "    ndf_b2['IP15'] = b2_collisionScheduleDF['# of LR in ATLAS/CMS']\n",
    "    ndf_b2['IP2']  = b2_collisionScheduleDF['# of LR in ALICE']\n",
    "    ndf_b2['IP8']  = b2_collisionScheduleDF['# of LR in LHCB']\n",
    "    ndf_b2.index   = b2_collisionScheduleDF.index\n",
    "    \n",
    "    return ndf_b1, ndf_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "toc": {
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
